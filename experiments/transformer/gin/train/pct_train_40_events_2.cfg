import experiments.graph.data_loader
import experiments.graph.dataset
import ariadne.pct.model

### experiment setup ###
experiment.model = @PCTSegment
experiment.criterion = @PerceiverFocalLoss
experiment.metrics = [
#    @transformer.precision,
#    @transformer.recall,
#    @transformer.f1_score,
    @transformer.true_acc,
    @transformer.fake_acc
]
experiment.optimizer = @Lamb
experiment.data_loader = @CloudDataLoader
experiment.epochs = 200
experiment.fp16_training = False
experiment.random_seed = 42
experiment.num_gpus = 1


CloudDataLoader.dataset = @CloudDataset
CloudDataLoader.collate_fn =  @voxel_collate_fn  # @voxel_collate_fn #
CloudDataLoader.n_train = 2000
CloudDataLoader.n_valid = 500
CloudDataLoader.batch_size = 1
# dataset
CloudDataset.input_dir = "/lustre/home/user/p/pgonchar/data/spd/cloud_40_event_chunk_eff_noise/"  # with set of 1 event normalized by -1,1
CloudDataset.n_samples = 2500

### model ###
Performer.n_feat = 3

HFPerceiver.d_latents = 64
HFPerceiver.d_model = 64
HFPerceiver.num_heads = 2
HFPerceiver.num_latents = 248

### loss ###
PerceiverFocalLoss.alpha = 0.25   # 0.5 / 0.1
PerceiverFocalLoss.gamma = 2   # 0.5 / 0.1
### optimizer ###
Lamb.lr = 0.0001
AdamW.lr = 0.0003
AdamW.weight_decay = 0.0001

voxel_collate_fn.shuffle = True
voxel_collate_fn.sample_len = 512
voxel_collate_fn.vx = 0.2
voxel_collate_fn.vy = 0.2
voxel_collate_fn.vz = 0.2

PCTSegment.n_points = 512
PCTSegment.input_channels = 6

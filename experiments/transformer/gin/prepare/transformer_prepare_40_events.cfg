preprocess.target_processor = @CloudProcessor
preprocess.output_dir = 'data/spd/cloud_40_event_chunk_eff_noise'
preprocess.ignore_asserts = True

#parse.input_file_mask='data/bes3/events/3.txt'
parse.input_file_mask='data/spd/100000_0.98.tsv'

parse.csv_params={
                    "sep": '\s+',
                    #"nrows": 10000,
                    "encoding": 'utf-8',
                    "names":  ['event',  'x', 'y', 'z', 'station',
                               'track', 'px', 'py', 'pz', 'X0', 'Y0', 'Z0', 'label']
                 }

### events_quantity:
# '1..10' (list of events with these indexes)
# or ':' (all events from df)
# or single index '3'
parse.events_quantity = ':'

# preprocessor
CloudProcessor.transforms = [
    @ConstraintsNormalize()
]
CloudProcessor.n_events_per_chunk = 40
#### transformations
DropShort.num_stations=3
ConstraintsNormalize.use_global_constraints = True
#ConstraintsNormalize.columns=('r', 'phi', 'z')
#ConstraintsNormalize.constraints = {
#    'r': [270., 580.], 'phi': [-3.15, 3.15], 'z': [-2386., 2386.]
#}
ConstraintsNormalize.columns=('x', 'y', 'z')
ConstraintsNormalize.constraints = {
    'x': [-851., 851.], 'y': [-851., 851.], 'z': [-2386., 2386.]
}

Normalize.columns=('x', 'y', 'z')